---
title: "Conditional calibration slope"
author: "Gergely Talyigas"
date: "26/04/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
```


## Necessary functions
```{r}
# The function generates data from a simple logistic model
generate_data <- function(n, beta){
  n_pred <- length(beta) - 1 #numper of predictors
  x <- matrix(rnorm(n*n_pred), n, n_pred) #generated x
  design_matrix <- cbind(1, x)
  
  #true probabilities from logit model
  p <- as.numeric(1/(1+exp(- design_matrix %*% beta))) 
  #drawing outcomes from Bernoulli distribution
  y <- rbinom(n, 1, p) 
  dat <- as.data.frame(x)
  dat$y <- y; dat$p <- p
  return(dat)
}


logit <- function (p) log(p/(1 - p))

cox_calibration <- function(y, prob){
  #if there is perfect calibration, the output is NA
  if (max(prob[y == 0]) < min(prob[y == 1])){
      return(list(slope = NA, intercept = NA))
  }
  dat <- data.frame(e = prob, o = y)
  dat$e[dat$e < 0.0000000001] = 0.0000000001
  dat$e[dat$e > 0.9999999999] = 0.9999999999
  #transform the probabilites
  dat$logite <- logit(dat$e)
  
  mfit = glm(formula = o~logite, 
             family = binomial(link = "logit"), dat)
  
  return(list(slope = as.numeric(mfit$coefficients[2]),
              intercept = as.numeric(mfit$coefficients[1])))
}
```

### checking the functions
```{r}
set.seed(26042021)
n <- 100
beta <- c(-0.3, 1, -1, .3) #using 3 predictors

full_data <- generate_data(n, beta)
sum(full_data$y) #We have 45 events

#fitting the model
logitm <- glm(y ~. -p, family = "binomial", data = full_data)
summary(logitm) 

#The model is fairly close to the true data generating model

external_data <- generate_data(n, beta)
pred <- predict(logitm, external_data, type="response")
cox_calibration(external_data$y, pred)
```


### The function for simulation
```{r}
simulate_different_sample_size <- function(n_sim, external_sizes, beta, n_training){

  
  slope_df <- as.data.frame(matrix(NA, n_sim, length(external_sizes)))
  intercept_df <- as.data.frame(matrix(NA, n_sim, length(external_sizes)))
  names(slope_df) <- paste("n_", external_sizes, sep = "")
  names(intercept_df) <- paste("n_", external_sizes, sep = "")
  
  for(es_index in 1:length(external_sizes)){
    sample_size <- external_sizes[es_index]
    
    for (i in 1:n_sim){
      full_data <- generate_data(n_training, beta)
      logitm <- glm(y ~. -p, family = "binomial", data = full_data)
      
      external_data <- generate_data(sample_size, beta)
      pred <- predict(logitm, external_data, type="response")
      cox_cal <- cox_calibration(external_data$y, pred)
      slope_df[i, es_index] <- cox_cal[1]
      intercept_df[i, es_index] <- cox_cal[2]
    }

  }
  return(list(slope = slope_df, intercept = intercept_df))
}
```

### Running the simulations
```{r}
set.seed(15081924)
n_training <- 100 #relatively small sample size but almost always EPV > 10
beta <- c(-0.3, 1, -1, .3) #using 3 predictors

n_sim <- 1000 #Running it with bigger sample gives similar results
external_sample_sizes <- c(20, 50, 100, 200, 500, 1000, 2000) 

sim_results <- simulate_different_sample_size(n_sim, external_sample_sizes,
                                              beta, n_training)
```
The warning occurs due to the small sample size when n = 20

```{r}
#for n = 20, separation occured 8 times during the simulation
sum(is.na(sim_results$slope$n_20)) 
#for n > 20, it did not occur
sum(is.na(sim_results$slope)) - sum(is.na(sim_results$slope$n_20))
```


```{r}
(expected_slope <- apply(sim_results$slope, 2, mean, na.rm = TRUE))
(median_slope <- apply(sim_results$slope, 2, median, na.rm = TRUE))
```
As we can see, both the mean and median is decreasing with increasing external sample size. From n = 500 to n = 2000 the variance from the logistic fit on the training data becomes too big to see the effect of the external sample size

```{r}
(expected_intercept <- apply(sim_results$intercept, 2, mean, na.rm = TRUE))
(median_intercept <- apply(sim_results$intercept, 2, median, na.rm = TRUE))
```
Interestingly all the values are negative, but they are still very close to 0, so I don't think this is problematic. Also, there is no clear pattern in the values, so the conditional intercept seems to have independent expected value from the sample size

Some visualizations to see the distributions of the conditional slope
```{r}
hist(sim_results$slope$n_20, 50)
#strongly skewed so omitted from the next plot
ggplot(stack(sim_results$slope[,2:7]), aes(x = ind, y = values)) +
  geom_boxplot()


slope_df <- stack(sim_results$slope[c("n_50", "n_200", "n_1000")])

ggplot(slope_df, aes(x = values, fill = ind)) +
  geom_histogram(position = "identity", alpha = 0.3, bins = 50)
```



